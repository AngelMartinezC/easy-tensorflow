{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classifier (Logistic Regression)\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This tutorial covers the implementation of a simple linear model using TensorFlow. We will implement this model for classifying images of hand-written digits from the so-called MNIST data-set. The structure of the network is presented in the following figure.\n",
    "\n",
    "\n",
    "<img src=\"files/files/linear_classifier.png\">\n",
    "\n",
    "\n",
    "___Fig. 1-___ Sample Logistic Regression structure implemented for classifying MNIST digits \n",
    "\n",
    "You should be familiar with basic linear algebra, Machine Learning and classification. To specifically learn about the linear classifiers, read [this](https://cs231n.github.io/linear-classify/) article.\n",
    "\n",
    "Technically, in a linear model we will use the simplest function to predict the label $\\mathbf{y_i}$ of the image $\\mathbf{x_i}$. We'll do so by using a linear mapping like $f(\\mathbf{x_i}, \\mathbf{W}, \\mathbf{b})=\\mathbf{W}\\mathbf{x_i}+\\mathbf{b}$ where $\\mathbf{W}$ and $\\mathbf{b}$ are called weight matrix and bias vector respectively. \n",
    " \n",
    "\n",
    "\n",
    "## 0. Import the required libraries:\n",
    "We will start with importing the required Python libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the MNIST data\n",
    "\n",
    "For this tutorial we use the MNIST dataset. MNIST is a dataset of handwritten digits. If you are into machine learning, you might have heard of this dataset by now. MNIST is kind of benchmark of datasets for deep learning and is easily accesible through Tensorflow\n",
    "\n",
    "The dataset contains 55,000 examples for training, 5,000 examples for validation and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. For simplicity, each image has been flattened and converted to a 1-D numpy array of 784 features (28*28).\n",
    "\n",
    "<img src=\"files/files/mnist.png\">\n",
    "\n",
    "\n",
    "If you want to know more about the MNIST dataset you can check __Yann Lecun__'s [website](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "### 1.1. Data dimension\n",
    "Here, we specify the dimensions of the images which will be used in several places in the code below. Defining these variables makes it easier (compared with using hard-coded number all throughout the code) to modify them later. Ideally these would be inferred from the data that has been read, but here we will just write the numbers.\n",
    "\n",
    "It's important to note that in a linear model, we have to flatten the input images into a vector. Here, each of the $28\\times28$ images are flattened into a $1\\times784$ vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h = img_w = 28             # MNIST images are 28x28\n",
    "img_size_flat = img_h * img_w  # 28x28=784, the total number of pixels\n",
    "n_classes = 10                 # Number of classes, one class per digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Helper functions to load the MNIST data\n",
    "\n",
    "In this section, we'll write the function which automatically loads the MNIST data and returns it in our desired shape and format. If you wanna learn more about loading your data, you may read our __How to Load Your Data in TensorFlow __ tutorial which explains all the available methods to load your own data; no matter how big it is. \n",
    "\n",
    "Here, we'll simply write a function (load_data) which has two modes: train (which loads the training and validation images and their corresponding labels) and test (which loads the test images and their corresponding labels). \n",
    "\n",
    "Other than a function for loading the images and corresponding labels, we define two more functions:\n",
    "\n",
    "1. __randomize__: which randomizes the order of images and their labels. This is important to make sure that the input images are sorted in a completely random order. Moreover, at the beginning of each __epoch__, we will re-randomize the order of data samples to make sure that the trained model is not sensitive to the order of data.\n",
    "\n",
    "2. __get_next_batch__: which only selects a few number of images determined by the batch_size variable (if you don't know why, read about Stochastic Gradient Method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(mode='train'):\n",
    "    \"\"\"\n",
    "    Function to (download and) load the MNIST data\n",
    "    :param mode: train or test\n",
    "    :return: images and the corresponding labels\n",
    "    \"\"\"\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    if mode == 'train':\n",
    "        x_train, y_train, x_valid, y_valid = mnist.train.images, mnist.train.labels, \\\n",
    "                                             mnist.validation.images, mnist.validation.labels\n",
    "        return x_train, y_train, x_valid, y_valid\n",
    "    elif mode == 'test':\n",
    "        x_test, y_test = mnist.test.images, mnist.test.labels\n",
    "    return x_test, y_test\n",
    "\n",
    "\n",
    "def randomize(x, y):\n",
    "    \"\"\" Randomizes the order of data samples and their corresponding labels\"\"\"\n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    shuffled_x = x[permutation, :]\n",
    "    shuffled_y = y[permutation]\n",
    "    return shuffled_x, shuffled_y\n",
    "\n",
    "\n",
    "def get_next_batch(x, y, start, end):\n",
    "    x_batch = x[start:end]\n",
    "    y_batch = y[start:end]\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Load the data and display the sizes\n",
    "Now we can use the defined helper function in __train__ mode which loads the train and validation images and their corresponding labels. We'll also display their sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Size of:\n",
      "- Training-set:\t\t55000\n",
      "- Validation-set:\t5000\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "x_train, y_train, x_valid, y_valid = load_data(mode='train')\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(y_train)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better sense of the data, let's checkout the shapes of the loaded arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:\t(55000, 784)\n",
      "y_train:\t(55000, 10)\n",
      "x_train:\t(5000, 784)\n",
      "y_valid:\t(5000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('x_train:\\t{}'.format(x_train.shape))\n",
    "print('y_train:\\t{}'.format(y_train.shape))\n",
    "print('x_train:\\t{}'.format(x_valid.shape))\n",
    "print('y_valid:\\t{}'.format(y_valid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, x_train and x_valid arrays contain 55000 and 5000 flattened images ( of size 28x28=784 values). y_train and y_valid contain the corresponding labels of the images in the training and validation set respectively. \n",
    "\n",
    "Based on the dimesnion of the arrays, for each image, we have 10 values as its label. Why? This technique is called __One-Hot Encoding__. This means the labels have been converted from a single number to a vector whose length equals the number of possible classes. All elements of the vector are zero except for the $i^{th}$ element which is one and means the class is $i$. For example, the One-Hot encoded labels for the first 5 images in the validation set are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the 10 values in each row represents the label assigned to that partiular image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameters\n",
    "\n",
    "Here, we have about 55,000 images in our training set. It takes a long time to calculate the gradient of the model using all these images. We therefore use __Stochastic Gradient Descent__ which only uses a small batch of images in each iteration of the optimizer. Let's define some of the terms usually used in this context:\n",
    "\n",
    "- __epoch__: one forward pass and one backward pass of __all__ the training examples\n",
    "- __batch size__: the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.\n",
    "- __iteration__: one forward pass and one backward pass of __one batch of images__ the training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "epochs = 10             # Total number of training epochs\n",
    "batch_size = 100        # Training batch size\n",
    "display_freq = 100      # Frequency of displaying the training results\n",
    "learning_rate = 0.001   # The optimization initial learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the above definitions, each epoch consists of $55,000/100=550$ iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper functions for creating new variables\n",
    "\n",
    "As explained (and also illustrated in Fig. 1), we need to define two variables $\\mathbf{W}$ and $\\mathbf{b}$ to construt our linear model. These are generally called model parameters and as explained in our [Tensor Types](https://github.com/easy-tensorflow/easy-tensorflow/blob/master/1_TensorFlow_Basics/Tutorials/2_Tensor_Types.ipynb) tutorial, we use __Tensorflow Variables__ of proper size and initialization to define them.The following functions are written to be later used for generating the weight and bias variables of the desired shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    \"\"\"\n",
    "    Create a weight variable with appropriate initialization\n",
    "    :param name: weight name\n",
    "    :param shape: weight shape\n",
    "    :return: initialized weight variable\n",
    "    \"\"\"\n",
    "    initer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "    return tf.get_variable('W',\n",
    "                           dtype=tf.float32,\n",
    "                           shape=shape,\n",
    "                           initializer=initer)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    \"\"\"\n",
    "    Create a bias variable with appropriate initialization\n",
    "    :param name: bias variable name\n",
    "    :param shape: bias variable shape\n",
    "    :return: initialized bias variable\n",
    "    \"\"\"\n",
    "    initial = tf.constant(0., shape=shape, dtype=tf.float32)\n",
    "    return tf.get_variable('b',\n",
    "                           dtype=tf.float32,\n",
    "                           initializer=initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create the network graph\n",
    "### 4.1. Placeholders for the inputs (x) and corresponding labels (y)\n",
    "\n",
    "First we need to define the proper tensors to feed in the input values to our model. As explained in the [Tensor Types](https://github.com/easy-tensorflow/easy-tensorflow/blob/master/1_TensorFlow_Basics/Tutorials/2_Tensor_Types.ipynb) tutorial, placeholder variable is the suitable choice for the input images and corresponding labels. This allows us to change the inputs (images and labels) to the TensorFlow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph for the linear model\n",
    "# Placeholders for inputs (x) and outputs(y)\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='X')\n",
    "y = tf.placeholder(tf.float32, shape=[None, n_classes], name='Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plceholder x is defined for the images; its data-type is set to float32 and the shape is set to [None, img_size_flat], where None means that the tensor may hold an arbitrary number of images with each image being a vector of length img_size_flat.\n",
    "\n",
    "\n",
    "Next we have y which is the placeholder variable for the true labels associated with the images that were input in the placeholder variable x. The shape of this placeholder variable is [None, num_classes] which means it may hold an arbitrary number of labels and each label is a vector of length num_classes which is 10 in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Build the model structure\n",
    "\n",
    "As explained in the introduction, a linear model uses the simplest function to predict the label $\\mathbf{y_i}$ of the image $\\mathbf{x_i}$. We'll do so by using a linear mapping like $f(\\mathbf{x_i}, \\mathbf{W}, \\mathbf{b})=\\mathbf{W}\\mathbf{x_i}+\\mathbf{b}$ where $\\mathbf{W}$ and $\\mathbf{b}$ are called weight matrix and bias vector respectively. \n",
    "\n",
    "Apart from the placeholder variables that were defined above and which serve as feeding input data into the model, model variables $\\mathbf{W}$ and $\\mathbf{b}$ must be defined using TensorFlow variables.They can be defined using the helper functions written in section 3 as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create weight matrix initialized randomely from N~(0, 0.01)\n",
    "W = weight_variable(shape=[img_size_flat, n_classes])\n",
    "\n",
    "# create bias vector initialized as zero\n",
    "b = bias_variable(shape=[n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\mathbf{W}$ is a 2-dimensional tensor (or matrix) with img_size_flat rows and n_classes columns, and $\\mathbf{b}$ is defined as a 1-dimensional tensor (or vector) of length n_classes.\n",
    "\n",
    "Now it's time to create the model by multiplying the images in the placeholder variable x with the weights ($\\mathbf{W}$) and then adds the biases ($\\mathbf{b}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_logits = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a matrix of shape [None, n_classes] because x has shape [None, img_size_flat] and weights has shape [img_size_flat, n_classes], so the multiplication of those two matrices is a matrix with shape [None, num_classes] and then the biases vector is added to each row of that matrix. As explained earlier, __None__ is used so that we can feed any number of images to the defined placeholders x and y.\n",
    "\n",
    "\n",
    "Now logits is a matrix with None (equal to the desired number of images fed at each time) rows and n_classes columns, where the element of the $i$'th row and $j$'th column is an estimate of how likely the $i$'th input image is to be of the $j$'th class.\n",
    "\n",
    "However, these estimates are a bit rough and difficult to interpret because the numbers may be very small or large, so we want to normalize them so that each row of the logits matrix sums to one, and each element is limited between zero and one. This is calculated using the so-called softmax function and the result is stored in y_pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(output_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred is a Tensor of shape [None, n_classes] which is similar to that of the output_logits and, more importantly, true labels (y placeholder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Define the predicted class\n",
    "The predicted class can be calculated from the y_pred matrix by taking the index of the largest element in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predictions\n",
    "cls_prediction = tf.argmax(output_logits, axis=1, name='predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Define the cost function\n",
    "\n",
    "To make the model better at classifying the input images, we must somehow change the variables for weights and biases. In neural networks, this is done through the __backpropagation__ mechansim. To start this mechansim, we first need to know how well the model currently performs by comparing the predicted output of the model y_pred to the desired output y_true.\n",
    "\n",
    "The __cross-entropy__ is a performance measure most commonly used in classification task. It is a continuous function that is always positive and if the predicted output of the model exactly matches the desired output then the cross-entropy equals zero. The goal of optimization is therefore to minimize the cross-entropy so it gets as close to zero as possible by changing the weights and biases of the model.\n",
    "\n",
    "TensorFlow has a built-in function for calculating the cross-entropy. Note that it uses the values of the logits because it also calculates the softmax internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cross-entropy for each image fed to x\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output tensor cross_entropy if of shape [None, n_classes].\n",
    "\n",
    "We have now calculated the cross-entropy for each of the image classifications so we have a measure of how well the model performs on each image individually. But in order to use the cross-entropy to guide the optimization of the model's variables we need a single scalar value, so we simply take the average of the cross-entropy for all the image classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average loss function over images fed to x\n",
    "loss = tf.reduce_mean(cross_entropy, name='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Define the optimizer\n",
    "\n",
    "Now that we have a cost measure that must be minimized, we can then create an optimizer. While there are many choicecs predefined in TensorFlow (Find all of them [here](https://www.tensorflow.org/versions/r1.2/api_guides/python/train#Optimizers), we'll use ADAM which is one of the most popular and powerful ones. The step-size (commonly known as learning_rate) is set to learning_rate=0.001 (defined in section 2).\n",
    "\n",
    "Note that optimization is not performed at this point. In fact, nothing is calculated at all, we just add the optimizer-object to the TensorFlow graph for later execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op').minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Define a performance measurment quantity (i.e. accuracy)\n",
    "We also need a performance measure to display the progress to the user. Accuracy is the usual one in the case of classification task. It's defined as the fraction of images classified correctly from all images (usually in percentage). \n",
    "\n",
    "To calculate it, we first need to find which images are predicted correctly. This is done through a vector of booleans (named correct_prediction) which shows whether the predicted class equals the true class of each image or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean to check if each image is classified correctly (True) or not (False)\n",
    "correct_prediction = tf.equal(tf.argmax(output_logits, 1), tf.argmax(y, 1), name='correct_pred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can calculate the classification accuracy by first type-casting the vector of booleans to floats (using tf.cast), so that False becomes 0 and True becomes 1, and then calculating the average of these numbers. The code for this part is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy function\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7. Op for initializing all variables\n",
    "The variables for weights and biases must be initialized before we start optimizing them. TensorFlow has it's own built-in operation which automatically initializes all the defined variables of the Graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the op for initializing all variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again note that this line of code doesn't initalize the variables! we're still creating the graph; similar to assembling the building blocks together, not running any of the operations. To initialize the variables, we need to run the created __init__ operation in a session. This is done in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run the session and start Training\n",
    "Once we're done creating the TensorFlow __graph__, we have to create a TensorFlow __session__ which is used to execute the graph (if graph-session idea is not clear to you, read our graph-session tutorial [here](https://github.com/easy-tensorflow/easy-tensorflow/blob/master/1_TensorFlow_Basics/Tutorials/1_Graph_and_Session.ipynb)). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables for weights and biases must be initialized before we start optimizing them. This can be done by simply running the defined __init__ operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the training epochs to gradually improve the weights and biases of the model. As explained, each epoch contains several iterations where in each iteration, a new batch of data is selected from the training-set and then TensorFlow executes the optimizer using those training samples. We can also perform a model evaluation at the end of each epoch to see how the model performs on never-before seen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "iter   0:\t Loss=2.25,\tTraining Accuracy=31.0%\n",
      "iter 100:\t Loss=0.75,\tTraining Accuracy=83.0%\n",
      "iter 200:\t Loss=0.49,\tTraining Accuracy=89.0%\n",
      "iter 300:\t Loss=0.32,\tTraining Accuracy=95.0%\n",
      "iter 400:\t Loss=0.32,\tTraining Accuracy=94.0%\n",
      "iter 500:\t Loss=0.32,\tTraining Accuracy=93.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 1, validation loss: 0.41, validation accuracy: 88.2%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 2\n",
      "iter   0:\t Loss=0.32,\tTraining Accuracy=90.0%\n",
      "iter 100:\t Loss=0.34,\tTraining Accuracy=91.0%\n",
      "iter 200:\t Loss=0.36,\tTraining Accuracy=93.0%\n",
      "iter 300:\t Loss=0.31,\tTraining Accuracy=93.0%\n",
      "iter 400:\t Loss=0.28,\tTraining Accuracy=93.0%\n",
      "iter 500:\t Loss=0.25,\tTraining Accuracy=95.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 2, validation loss: 0.34, validation accuracy: 90.2%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 3\n",
      "iter   0:\t Loss=0.20,\tTraining Accuracy=97.0%\n",
      "iter 100:\t Loss=0.33,\tTraining Accuracy=88.0%\n",
      "iter 200:\t Loss=0.25,\tTraining Accuracy=95.0%\n",
      "iter 300:\t Loss=0.31,\tTraining Accuracy=90.0%\n",
      "iter 400:\t Loss=0.43,\tTraining Accuracy=87.0%\n",
      "iter 500:\t Loss=0.28,\tTraining Accuracy=93.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 3, validation loss: 0.32, validation accuracy: 90.6%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 4\n",
      "iter   0:\t Loss=0.30,\tTraining Accuracy=91.0%\n",
      "iter 100:\t Loss=0.37,\tTraining Accuracy=87.0%\n",
      "iter 200:\t Loss=0.33,\tTraining Accuracy=93.0%\n",
      "iter 300:\t Loss=0.40,\tTraining Accuracy=91.0%\n",
      "iter 400:\t Loss=0.33,\tTraining Accuracy=93.0%\n",
      "iter 500:\t Loss=0.37,\tTraining Accuracy=86.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 4, validation loss: 0.30, validation accuracy: 91.2%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 5\n",
      "iter   0:\t Loss=0.27,\tTraining Accuracy=94.0%\n",
      "iter 100:\t Loss=0.50,\tTraining Accuracy=90.0%\n",
      "iter 200:\t Loss=0.37,\tTraining Accuracy=91.0%\n",
      "iter 300:\t Loss=0.26,\tTraining Accuracy=92.0%\n",
      "iter 400:\t Loss=0.29,\tTraining Accuracy=94.0%\n",
      "iter 500:\t Loss=0.18,\tTraining Accuracy=96.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 5, validation loss: 0.30, validation accuracy: 90.9%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 6\n",
      "iter   0:\t Loss=0.60,\tTraining Accuracy=89.0%\n",
      "iter 100:\t Loss=0.42,\tTraining Accuracy=86.0%\n",
      "iter 200:\t Loss=0.21,\tTraining Accuracy=92.0%\n",
      "iter 300:\t Loss=0.32,\tTraining Accuracy=91.0%\n",
      "iter 400:\t Loss=0.14,\tTraining Accuracy=98.0%\n",
      "iter 500:\t Loss=0.42,\tTraining Accuracy=90.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 6, validation loss: 0.29, validation accuracy: 91.2%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 7\n",
      "iter   0:\t Loss=0.27,\tTraining Accuracy=94.0%\n",
      "iter 100:\t Loss=0.15,\tTraining Accuracy=95.0%\n",
      "iter 200:\t Loss=0.16,\tTraining Accuracy=95.0%\n",
      "iter 300:\t Loss=0.30,\tTraining Accuracy=89.0%\n",
      "iter 400:\t Loss=0.18,\tTraining Accuracy=94.0%\n",
      "iter 500:\t Loss=0.16,\tTraining Accuracy=95.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 7, validation loss: 0.29, validation accuracy: 91.6%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 8\n",
      "iter   0:\t Loss=0.19,\tTraining Accuracy=98.0%\n",
      "iter 100:\t Loss=0.23,\tTraining Accuracy=93.0%\n",
      "iter 200:\t Loss=0.17,\tTraining Accuracy=94.0%\n",
      "iter 300:\t Loss=0.30,\tTraining Accuracy=92.0%\n",
      "iter 400:\t Loss=0.28,\tTraining Accuracy=92.0%\n",
      "iter 500:\t Loss=0.29,\tTraining Accuracy=89.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 8, validation loss: 0.28, validation accuracy: 91.9%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 9\n",
      "iter   0:\t Loss=0.29,\tTraining Accuracy=90.0%\n",
      "iter 100:\t Loss=0.33,\tTraining Accuracy=92.0%\n",
      "iter 200:\t Loss=0.17,\tTraining Accuracy=94.0%\n",
      "iter 300:\t Loss=0.37,\tTraining Accuracy=90.0%\n",
      "iter 400:\t Loss=0.38,\tTraining Accuracy=90.0%\n",
      "iter 500:\t Loss=0.36,\tTraining Accuracy=93.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 9, validation loss: 0.29, validation accuracy: 91.4%\n",
      "---------------------------------------------------------\n",
      "Training epoch: 10\n",
      "iter   0:\t Loss=0.25,\tTraining Accuracy=91.0%\n",
      "iter 100:\t Loss=0.23,\tTraining Accuracy=93.0%\n",
      "iter 200:\t Loss=0.30,\tTraining Accuracy=93.0%\n",
      "iter 300:\t Loss=0.38,\tTraining Accuracy=90.0%\n",
      "iter 400:\t Loss=0.23,\tTraining Accuracy=94.0%\n",
      "iter 500:\t Loss=0.20,\tTraining Accuracy=95.0%\n",
      "---------------------------------------------------------\n",
      "Epoch: 10, validation loss: 0.29, validation accuracy: 91.5%\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "# Number of training iterations in each epoch\n",
    "num_tr_iter = int(len(y_train) / batch_size)\n",
    "for epoch in range(epochs):\n",
    "    print('Training epoch: {}'.format(epoch + 1))\n",
    "    x_train, y_train = randomize(x_train, y_train)\n",
    "    for iteration in range(num_tr_iter):\n",
    "        global_step += 1\n",
    "        start = iteration * batch_size\n",
    "        end = (iteration + 1) * batch_size\n",
    "        x_batch, y_batch = get_next_batch(x_train, y_train, start, end)\n",
    "\n",
    "        # Run optimization op (backprop)\n",
    "        feed_dict_batch = {x: x_batch, y: y_batch}\n",
    "        sess.run(optimizer, feed_dict=feed_dict_batch)\n",
    "\n",
    "        if iteration % display_freq == 0:\n",
    "            # Calculate and display the batch loss and accuracy\n",
    "            loss_batch, acc_batch = sess.run([loss, accuracy],\n",
    "                                             feed_dict=feed_dict_batch)\n",
    "\n",
    "            print(\"iter {0:3d}:\\t Loss={1:.2f},\\tTraining Accuracy={2:.01%}\".\n",
    "                  format(iteration, loss_batch, acc_batch))\n",
    "\n",
    "    # Run validation after every epoch\n",
    "    feed_dict_valid = {x: x_valid[:1000], y: y_valid[:1000]}\n",
    "    loss_valid, acc_valid = sess.run([loss, accuracy], feed_dict=feed_dict_valid)\n",
    "    print('---------------------------------------------------------')\n",
    "    print(\"Epoch: {0}, validation loss: {1:.2f}, validation accuracy: {2:.01%}\".\n",
    "          format(epoch + 1, loss_valid, acc_valid))\n",
    "    print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, the validation accuracy goes above 91% which is quite good (given that it's a linear model).\n",
    "\n",
    "\n",
    "## 6. Test\n",
    "\n",
    "Now that we're done with the training, let's test the model performance to see how it performs on the test set. We can also write some simple functions to plot some of the results. \n",
    "\n",
    "### 6.1. Helper functions for plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None, title=None):\n",
    "    \"\"\"\n",
    "    Create figure with 3x3 sub-plots.\n",
    "    :param images: array of images to be plotted, (9, img_h*img_w)\n",
    "    :param cls_true: corresponding true labels (9,)\n",
    "    :param cls_pred: corresponding true labels (9,)\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(9, 9))\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(28, 28), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            ax_title = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            ax_title = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        ax.set_title(ax_title)\n",
    "\n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    if title:\n",
    "        plt.suptitle(title, size=20)\n",
    "    plt.show(block=False)\n",
    "\n",
    "\n",
    "def plot_example_errors(images, cls_true, cls_pred, title=None):\n",
    "    \"\"\"\n",
    "    Function for plotting examples of images that have been mis-classified\n",
    "    :param images: array of all images, (#imgs, img_h*img_w)\n",
    "    :param cls_true: corresponding true labels, (#imgs,)\n",
    "    :param cls_pred: corresponding predicted labels, (#imgs,)\n",
    "    \"\"\"\n",
    "    # Negate the boolean array.\n",
    "    incorrect = np.logical_not(np.equal(cls_pred, cls_true))\n",
    "\n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    incorrect_images = images[incorrect]\n",
    "\n",
    "    # Get the true and predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "    cls_true = cls_true[incorrect]\n",
    "\n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=incorrect_images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9],\n",
    "                title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Run the test and plot some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "---------------------------------------------------------\n",
      "Test loss: 0.27, test accuracy: 92.0%\n",
      "---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAI7CAYAAACJEmNgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 648x648 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAI7CAYAAACJEmNgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCAoCABB+AgkorrHlCOT+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 648x648 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the network after training\n",
    "# Accuracy\n",
    "x_test, y_test = load_data(mode='test')\n",
    "feed_dict_test = {x: x_test[:1000], y: y_test[:1000]}\n",
    "loss_test, acc_test = sess.run([loss, accuracy], feed_dict=feed_dict_test)\n",
    "print('---------------------------------------------------------')\n",
    "print(\"Test loss: {0:.2f}, test accuracy: {1:.01%}\".format(loss_test, acc_test))\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Plot some of the correct and misclassified examples\n",
    "cls_pred = sess.run(cls_prediction, feed_dict=feed_dict_test)\n",
    "cls_true = np.argmax(y_test[:1000], axis=1)\n",
    "plot_images(x_test, cls_true, cls_pred, title='Correct Examples')\n",
    "plot_example_errors(x_test[:1000], cls_true, cls_pred, title='Misclassified Examples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing! 92% on test data.\n",
    "\n",
    "Thanks for reading this turorial. I hope this post has helped you to learn how to build a linear classifier from scratch in TensorFlow. In the next tutorial, we'll add TensorBoard operataions to this code to be able to visualize the network graph and its training performance in TensorBoard!\n",
    "\n",
    "If you have any questions, feel free to leave a comment in our webpage. You can also send us feedback through the [contact us](http://www.easy-tensorflow.com/contacts) page."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
